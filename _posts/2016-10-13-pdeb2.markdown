---
layout: post
title:  "Clinton and Trump Second Presidential Debate Sentiment Analysis"
date:   2016-10-13 00:00:00
categories: r, data, graphs, politics, debates, clinton, trump, general election
---

**Overview**: 

Sentiment Analysis of the Second Presidential Debate on 10/9/2016: 

![Both Debates Comparison](http://khasachi.com/images/ctCompBar.png)
![Second Debates Comparison](http://khasachi.com/images/ctdeb2.png)
![Clinton Debates Comparison](http://khasachi.com/images/cCompBar.png)
![Trump Debates Comparison](http://khasachi.com/images/tCompBar.png)

**Sentiment Comparison Results**: 

Clinton, Debate 2 vs Debate 1 Sentiment Comparison: 

Sentiments Used Less Frequently (percentage points, from highest to lowest change): fear, sadness, negative, disgust

Sentiments Used More Frequently (percentage points, from highest to lowest change): positive, trust, surprise, joy, anticipation, anger

Trump, Debate 2 vs Debate 1 Sentiment Comparison: 

Sentiments Used Less Frequently (percentage points, from highest to lowest change): 
* positive 
* negative
* joy
* sadness 
* anticipation

Sentiments Used More Frequently (percentage points, from highest to lowest change):
* anger
* trust
* surprise
* digust
* fear

Clinton vs Trump, Debate 1 Sentiment Comparison: 

Sentiments Clinton Expressed Less Frequently than Trump (percentage points, from highest to lowest difference): 
* negative
* anger
* sadness
* disgust
* joy
* surprise
* fear

Sentiments Clinton Expressed More Frequently than Trump (percentage points, from highest to lowest difference):
* trust
* positive
* anticipation

Clinton vs Trump, Debate 2 Sentiment Comparison: 

Sentiments Clinton Expressed Less Frequently than Trump (percentage points, from highest to lowest difference): 
* disgust
* anger
* negative
* fear
* sadness
* surprise

Sentiments Clinton Expressed More Frequently than Trump (percentage points, from highest to lowest difference): 
* positive
* trust
* anticipation
* joy

**Total Words Comparison**

Second Debate: 

Clinton: 6,334 words

Trump: 7,325 words

Raddatz: 1,283 words

Cooper: 1,116 words


First Debate: 

Clinton: 6,332 words

Trump: 8,675 words

Holt: 1,790 words

**Table of Results** 
![Table of Results](http://khasachi.com/images/comTable.PNG)

**Getting the Data**

I obtained transcripts of the debates from the New York Times' trancript [Second Presidential Debate](http://www.nytimes.com/2016/10/10/us/politics/transcript-second-debate.html?_r=0).

**Getting the Results**
I used R to perform the analysis. Specifically, I used the code provided in [this](http://varianceexplained.org/r/trump-tweets/) post by David Robinson to perform the sentiment analysis. I then used R to create functions to automate total word counts; perform the sentiment analysis (again using the code in Varience Explained post by Robinson to do all the heavy lifting); reshape data to reshape it for the bar chart; and to create the bar chart. 

**R Code**

TOTAL WORDS

    totalWords <- function(directory, person_spk) {
      wd <- getwd()
      dir <- paste(wd,"/",directory,sep="")
      db_text <- read.csv(dir)
      atext <- subset(db_text, person == person_spk)
      atext$total <- str_count(atext$text, '\\s+')+1
      dword_count <- sum(atext$total)
      dword_count  
    }

    c_tw <- totalWords("Book2ct.csv", 'CLINTON')
    t_tw <- totalWords("Book2ct.csv", 'TRUMP')
    r_tw <- totalWords("Book2ct.csv", 'RADDATZ')
    a_tw <- totalWords("Book2ct.csv", 'COOPER')

SENTIMENT ANALYSIS

The actual sentiment analysis function is from [this](http://varianceexplained.org/r/trump-tweets/) post

    sentmt <- function(directory, person_spk) {
      wd <- getwd()
  
      dir <- paste(wd,"/",directory,sep="")
      db_text <- read.csv(dir)
  
      atext <- subset(db_text, person == person_spk)
  
      reg <- "([^A-Za-z\\d#@']|'(?![A-Za-z\\d#@]))"
  
      nrc <- sentiments %>%
        filter(lexicon == "nrc") %>%
        dplyr::select(word, sentiment) 
  
      deb_words <- atext %>%
        filter(!str_detect(text, '^"')) %>%
        unnest_tokens(word, text, token = "regex", pattern = reg) %>%
        filter(!word %in% stop_words$word,
           str_detect(word, "[a-z]"))
      freq_words <- data.frame(table(deb_words))
      freq_words <- subset(freq_words, person==person)
      freq_words <- freq_words[order(-freq_words$Freq),]
      words_sentiment <- deb_words %>%
        inner_join(nrc, by = "word") %>%
        count(sentiment) %>%
        ungroup() %>%
        complete(sentiment,  fill = list(n = 0)) %>%
        group_by(sentiment) %>%
        summarize(words = sum(n)) %>%
        ungroup() 
  
      words_sentiment$words_perc <- ((words_sentiment$words)/sum(words_sentiment$words)*100)
      words_sentiment
    }
    
    ## Run ##

    c1_sentiment <- sentmt("ctdeb.csv",'C')
    t1_sentiment <- sentmt("ctdeb.csv",'T')
    c2_sentiment <- sentmt("Book2ct.csv",'CLINTON')
    t2_sentiment <- sentmt("Book2ct.csv",'TRUMP')
    
    ##MERGE FUNCTION

    mergestuff <- function(xMerge, yMerge) {
    primMerge <- merge(x=xMerge, y=yMerge, by = "sentiment", all.x = TRUE)
    sorted <- primMerge[order(-primMerge[,2]),]
    sorted
    }

    c12Mg <- mergestuff(c1_sentiment, c2_sentiment)
    t12Mg <- mergestuff(t1_sentiment, t2_sentiment)
    tcMg <- mergestuff(c_sentiment, t_sentiment)
    tc12Mg <- mergestuff(c12Mg, t12Mg)

    tc12Mg$clintonDebatesVar <- tc12Mg$`Clinton.per-deb2` - tc12Mg$`Clinton.per-deb1`
    tc12Mg$trumpDebatesVar <- tc12Mg$`Trump.per-deb2` - tc12Mg$`Trump.per-deb1`
    tc12Mg$CvsTDebate1Var <- tc12Mg$`Clinton.per-deb1` - tc12Mg$`Trump.per-deb1`
    tc12Mg$CvsTDebate2Var <- tc12Mg$`Clinton.per-deb2` - tc12Mg$`Trump.per-deb2`

    tc12Mg$`Clinton.per-deb1` <-  format(round(tc12Mg$`Clinton.per-deb1`, 2), nsmall = 2)
    tc12Mg$`Clinton.per-deb2` <-  format(round(tc12Mg$`Clinton.per-deb2`, 2), nsmall = 2)
    tc12Mg$`Trump.per-deb1` <-  format(round(tc12Mg$`Trump.per-deb1`, 2), nsmall = 2)
    tc12Mg$`Trump.per-deb2` <-  format(round(tc12Mg$`Trump.per-deb2`, 2), nsmall = 2)
    tc12Mg$clintonDebatesVar <-  format(round(tc12Mg$clintonDebatesVar, 2), nsmall = 2)
    tc12Mg$trumpDebatesVar <-  format(round(tc12Mg$trumpDebatesVar, 2), nsmall = 2)
    tc12Mg$CvsTDebate1Var <-  format(round(tc12Mg$CvsTDebate1Var, 2), nsmall = 2)
    tc12Mg$CvsTDebate2Var <-  format(round(tc12Mg$CvsTDebate2Var, 2), nsmall = 2)

BAR CHARTS

    ##Melt Function
    melting <- function(file,ons, id) {
    newdata <- file[id]
    mdata <- melt(newdata, id=c(ons))  
    }

    melt_tc <- melting(tcMg,"sentiment",c(1,3,5))
    melt_c12 <- melting(c12Mg,"sentiment",c(1,3,5))
    melt_t12 <- melting(t12Mg,"sentiment",c(1,3,5))

    melt_ct12 <- melting(tc12Mg,"sentiment",c(1,3,5,7,9))

    ##Bar Chart Function 
    make_bar <- function(file,blabels,legTitle, colorsbar) {
    label_dig <- round(file$value, digits=0)
    label_perc <- paste(label_dig, "%",sep="")
    ggplot(data=file, aes(x=sentiment, y=value, fill=variable)) +
        geom_bar(stat="identity", position=position_dodge()) + 
        scale_fill_manual(labels=blabels, name=legTitle, values=colorsbar) +
        geom_text(aes(label=label_perc),
                  position=position_dodge(width=0.9), vjust=-0.25, size=2.5 )
    }

    ctBar <- make_bar(melt_vp,c("Clinton", "Trump"), "2nd Debate", c("blue", "red"))
    cCompBar <- make_bar(melt_c12,c("Clinton-Deb1", "Clinton-Deb2"), "Debate Comparison", c("#9999ff", "blue"))
    tCompBar <- make_bar(melt_t12,c("Trump-Deb1", "Trump-Deb2"), "Debate Comparison", c("#ff9999", "red"))
    ctCompBar <- make_bar(melt_ct12,c("Clinton-Deb1", "Clinton-Deb2", "Trump-Deb1", "Trump-Deb2"), "Debate Comparison", c("#9999ff", "blue", "#ff9999", "red"))

